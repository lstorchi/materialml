{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(\"./data/FINAL_DATASET.xlsx\")\n",
    "\n",
    "for name in df.columns:\n",
    "    newname = name\n",
    "    # remove alla characted within two []\n",
    "    while \"[\" in newname:\n",
    "        start = newname.find(\"[\")\n",
    "        end = newname.find(\"]\")\n",
    "        newname = newname[:start] + newname[end+1:]\n",
    "    # remove end spaces and beginning spaces\n",
    "    newname = newname.strip()\n",
    "    # remove alla mathematical oipreators caharacters and spaces\n",
    "    newname = newname.replace(\" \", \"_\")\n",
    "    newname = newname.replace(\">\", \"gt\")\n",
    "    newname = newname.replace(\"<\", \"lt\")\n",
    "    newname = newname.replace(\"=\", \"eq\")\n",
    "    newname = newname.replace(\"+\", \"plus\")\n",
    "    newname = newname.replace(\"-\", \"minus\")\n",
    "    newname = newname.replace(\"*\", \"times\")\n",
    "    newname = newname.replace(\"/\", \"div\")\n",
    "    # rename columns in the dataframe\n",
    "    df.rename(columns={name: newname}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelname  = \"d33\"\n",
    "materialfeatures = ['octahedra_volume_min', 'octahedra_volume_max', 'octahedra_volume_avg',\n",
    "       'octahedra_meanangle_axis_min', 'octahedra_meanangle_axis_max',\n",
    "       'octahedra_meanangle_axis_avg', 'tilt_BOB_ip_min', 'tilt_BOB_ip_max',\n",
    "       'tilt_BOB_ip_avg', 'tilt_BOB_oop_min', 'tilt_BOB_oop_max',\n",
    "       'tilt_BOB_oop_avg', 'spageGroup_no', 'lattice_a', 'lattice_b',\n",
    "       'lattice_c', 'lattice_alfa', 'lattice_beta', 'lattice_gamma',\n",
    "       'volume_uc', 'volume_uc_per_atom', 'volume_ratio_ucVSoctahedra',\n",
    "       'tolerance_factor', 'ratio_outVSinplaneAVG', 'ratio_outVSinplanemin',\n",
    "       'ratio_outVSinplanemax', 'bond_lengthAA_min', 'bond_lengthAA_max',\n",
    "       'bond_lengthAA_avg', 'bond_lengthAB_min', 'bond_lengthAB_max',\n",
    "       'bond_lengthAB_avg', 'bond_lengthAO_min', 'bond_lengthAO_max',\n",
    "       'bond_lengthAO_avg', 'bond_lengthBO_min', 'bond_lengthBO_max',\n",
    "       'bond_lengthBO_avg', 'bond_lengthBB_min', 'bond_lengthBB_max',\n",
    "       'bond_lengthBB_avg', 'is_magnetic', #'is_metallic', 'is_perovskite', \n",
    "       #'P_0_z', \n",
    "       'P_0_z_muCdivcm2',]\n",
    "atomicfeatures = ['A_Z', 'A_group', 'A_valence',\n",
    "       'A_vecdivZ', 'A_n_d', 'A_atomic_volume_pymatgen', 'A_Rdce', 'A_Rdve',\n",
    "       'A_rs_max', 'A_rd_max', 'A_IE_ionization_energy',\n",
    "       'A_EA_electron_affinity', 'A_Mulliken', 'A_Pauling',\n",
    "       'A_MartynovminusBatsanov', 'A_atomic_radius_rahm', 'A_vdw_radius_uff',\n",
    "       'A_ionic_radius', 'B_Z', 'B_group', 'B_valence', 'B_vecdivZ', 'B_n_d',\n",
    "       'B_atomic_volume_pymatgen', 'B_Rdce', 'B_Rdve', 'B_rs_max', 'B_rd_max',\n",
    "       'B_IE_ionization_energy', 'B_EA_electron_affinity', 'B_Mulliken',\n",
    "       'B_Pauling', 'B_MartynovminusBatsanov', 'B_atomic_radius_rahm',\n",
    "       'B_vdw_radius_uff', 'B_residual_d', 'B_ionic_radius']\n",
    "\n",
    "Y = df[labelname]\n",
    "X = df[materialfeatures + atomicfeatures]\n",
    "X_mat = df[materialfeatures]\n",
    "X_atm = df[atomicfeatures]\n",
    "\n",
    "# classification labbel for the dataset splitted by value\n",
    "cutval = 5.0\n",
    "Y_class = []\n",
    "for y in Y:\n",
    "    if y < -1.0*cutval:\n",
    "        Y_class.append(0)\n",
    "    elif y > -1.0*cutval and y < cutval:\n",
    "        Y_class.append(1)\n",
    "    else:\n",
    "        Y_class.append(2)\n",
    "\n",
    "Y_class = np.array(Y_class)\n",
    "# print the number of values for each class\n",
    "print(\"Number of values in class 0: \", len(Y_class[Y_class==0]))\n",
    "print(\"Number of values in class 1: \", len(Y_class[Y_class==1]))\n",
    "print(\"Number of values in class 2: \", len(Y_class[Y_class==2]))\n",
    "\n",
    "\n",
    "print(\"min label: \", min(Y))\n",
    "print(\"max label: \", max(Y))\n",
    "print(\"Number of values   greater than 0: \", len(Y[Y>0]))\n",
    "print(\"Number of values     lower than 0: \", len(Y[Y<0]))\n",
    "print(\"Number of values       equal to 0: \", len(Y[Y==0]))\n",
    "print(\"Number of values   greater than 5: \", len(Y[Y>cutval]))\n",
    "print(\"Number of values    lower than -5: \", len(Y[Y<-1.0*cutval]))\n",
    "print(\"Number of values between -5 and 5: \", len(Y[(Y>-1.0*cutval) & (Y<cutval)]))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(Y, bins=100)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of the labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRCUT = 0.95\n",
    "corr = X.corr()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "for i in range(upper.shape[0]):\n",
    "    for j in range(upper.shape[1]):\n",
    "        if upper.iloc[i,j] > CORRCUT:\n",
    "            print(\"%30s %30s %5.2f\"%(upper.columns[i], \\\n",
    "                                     upper.columns[j], \\\n",
    "                                        upper.iloc[i,j]))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] >CORRCUT)]\n",
    "print(\"Dropping features: \", to_drop)\n",
    "X = X.drop(X[to_drop], axis=1)\n",
    "\n",
    "corr_mat = X_mat.corr()\n",
    "upper = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > CORRCUT)]\n",
    "print(\"Dropping features: \", to_drop)\n",
    "X_mat = X_mat.drop(X_mat[to_drop], axis=1)\n",
    "\n",
    "corr_atm = X_atm.corr()\n",
    "upper = corr_atm.where(np.triu(np.ones(corr_atm.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > CORRCUT)]\n",
    "print(\"Dropping features: \", to_drop)\n",
    "X_atm = X_atm.drop(X_atm[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build histograms for the features\n",
    "#for feature in X.columns:\n",
    "#    plt.figure(figsize=(10, 10))\n",
    "#    plt.hist(X[feature], bins=100)\n",
    "#    plt.xlabel(\"Value\")\n",
    "#    plt.ylabel(\"Frequency\")\n",
    "#    plt.title(\"Histogram of the feature: \"+feature)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build histogram for classes\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(Y_class, bins=3)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of the classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classification model using RF \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_class, test_size=0.2, random_state=42) \n",
    "accuracies = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    clf = RandomForestClassifier(n_estimators=ntrees, random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#plt.plot(range(10, 200, 10), accuracies)\n",
    "#plt.xlabel(\"Number of trees\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"Accuracy vs number of trees\")\n",
    "#plt.show()\n",
    "\n",
    "bestnumoftress = range(10, 200, 10)[accuracies.index(max(accuracies))]\n",
    "print(\"Best accuracy: \", max(accuracies), \" with \", range(10, 200, 10)[accuracies.index(max(accuracies))], \" trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a RF classification model using X_atm\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_atm, Y_class, test_size=0.2, random_state=42)\n",
    "accuracies = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    clf = RandomForestClassifier(n_estimators=ntrees, random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#plt.plot(range(10, 200, 10), accuracies)\n",
    "#plt.xlabel(\"Number of trees\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"Accuracy vs number of trees\")\n",
    "#plt.show()\n",
    "\n",
    "print(\"Best accuracy: \", max(accuracies), \" with \", range(10, 200, 10)[accuracies.index(max(accuracies))], \" trees\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a RF classification model using X_mat\\\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_mat, Y_class, test_size=0.2, random_state=42)\n",
    "accuracies = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    clf = RandomForestClassifier(n_estimators=ntrees, random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"Best accuracy: \", max(accuracies), \" with \", range(10, 200, 10)[accuracies.index(max(accuracies))], \" trees\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the RF classification model using X\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_class, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=bestnumoftress, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "testaccuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Test accuracy: \", testaccuracy)\n",
    "Y_pred = clf.predict(X_train)\n",
    "trainaccuracy = accuracy_score(Y_train, Y_pred)\n",
    "print(\"Train accuracy: \", trainaccuracy)\n",
    "overallaccuracy = accuracy_score(Y_class, clf.predict(X))   \n",
    "print(\"Overall accuracy: \", overallaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the feature importance not the best approach\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%2d) %-*s %f\"%(f+1, 30, X.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the trees of the RF\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import graphviz\n",
    "print(\"Number of trees: \", len(clf.estimators_))\n",
    "for i in range(3):\n",
    "    tree = clf.estimators_[i]\n",
    "    print(\"Tree \", i, \"Max depth: \", tree.tree_.max_depth)\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
