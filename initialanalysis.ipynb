{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(\"./data/FINAL_DATASET.xlsx\")\n",
    "\n",
    "for name in df.columns:\n",
    "    newname = name\n",
    "    # remove alla characted within two []\n",
    "    while \"[\" in newname:\n",
    "        start = newname.find(\"[\")\n",
    "        end = newname.find(\"]\")\n",
    "        newname = newname[:start] + newname[end+1:]\n",
    "    # remove end spaces and beginning spaces\n",
    "    newname = newname.strip()\n",
    "    # remove all mathematical oipreators caharacters and spaces\n",
    "    #newname = newname.replace(\" \", \"_\")\n",
    "    #newname = newname.replace(\">\", \"gt\")\n",
    "    #newname = newname.replace(\"<\", \"lt\")\n",
    "    #newname = newname.replace(\"=\", \"eq\")\n",
    "    #newname = newname.replace(\"+\", \"plus\")\n",
    "    #newname = newname.replace(\"-\", \"minus\")\n",
    "    #newname = newname.replace(\"*\", \"times\")\n",
    "    #newname = newname.replace(\"/\", \"div\")\n",
    "    # rename columns in the dataframe\n",
    "    #df.rename(columns={name: newname}, inplace=True)\n",
    "#for c in df.columns:\n",
    "#    print(c)\n",
    "# print a specific row number 168\n",
    "print(df.loc[167, \"label_structure\"])\n",
    "# remove all row after row 167\n",
    "df = df.iloc[:168, :]\n",
    "# print last row \n",
    "print(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelname  = \"d33\"\n",
    "materialfeatures = [\\\n",
    "    \"formal_charge_A-site\",\\\n",
    "    \"formal_charge_B-site\",\\\n",
    "    \"octahedra_volume_min\",\\\n",
    "    \"octahedra_volume_max\",\\\n",
    "    \"octahedra_volume_avg\",\\\n",
    "    \"octahedra_meanangle_axis_min\",\\\n",
    "    \"octahedra_meanangle_axis_max\",\\\n",
    "    \"octahedra_meanangle_axis_avg\",\\\n",
    "    \"tilt_BOB_ip_min\",\\\n",
    "    \"tilt_BOB_ip_max\",\\\n",
    "    \"tilt_BOB_ip_avg\",\\\n",
    "    \"tilt_BOB_oop_min\",\\\n",
    "    \"tilt_BOB_oop_max\",\\\n",
    "    \"tilt_BOB_oop_avg\",\\\n",
    "    \"spageGroup_no\",\\\n",
    "    \"lattice_a\",\\\n",
    "    \"lattice_b\",\\\n",
    "    \"lattice_c\",\\\n",
    "    \"lattice_alfa\",\\\n",
    "    \"lattice_beta\",\\\n",
    "    \"lattice_gamma\",\\\n",
    "    \"volume_uc\",\\\n",
    "    \"volume_uc_per_atom\",\\\n",
    "    \"volume_ratio_ucVSoctahedra\",\\\n",
    "    \"tolerance_factor\",\\\n",
    "    \"ratio_outVSinplaneAVG\",\\\n",
    "    \"ratio_outVSinplanemin\",\\\n",
    "    \"ratio_outVSinplanemax\",\\\n",
    "    \"bond_lengthAA_min\",\\\n",
    "    \"bond_lengthAA_max\",\\\n",
    "    \"bond_lengthAA_avg\",\\\n",
    "    \"bond_lengthAB_min\",\\\n",
    "    \"bond_lengthAB_max\",\\\n",
    "    \"bond_lengthAB_avg\",\\\n",
    "    \"bond_lengthAO_min\",\\\n",
    "    \"bond_lengthAO_max\",\\\n",
    "    \"bond_lengthAO_avg\",\\\n",
    "    \"bond_lengthBO_min\",\\\n",
    "    \"bond_lengthBO_max\",\\\n",
    "    \"bond_lengthBO_avg\",\\\n",
    "    \"bond_lengthBB_min\",\\\n",
    "    \"bond_lengthBB_max\",\\\n",
    "    \"bond_lengthBB_avg\",\\\n",
    "    \"is_magnetic\",\\\n",
    "    \"is_metallic\",\\\n",
    "    \"is_perovskite\"]\n",
    "atomicfeatures = [\\\n",
    "    \"A_Z\",\\\n",
    "    \"A_group\",\\\n",
    "    \"A_valence\",\\\n",
    "    \"A_vec/Z\",\\\n",
    "    \"A_n_d\",\\\n",
    "    \"A_atomic_volume pymatgen [cm3/mol]\",\\\n",
    "    \"A_Rdce [Å]\",\\\n",
    "    \"A_Rdve  [Å]\",\\\n",
    "    \"A_rs_max  [Å]\",\\\n",
    "    \"A_rd_max  [Å]\",\\\n",
    "    \"A_IE ionization energy [eV]\",\\\n",
    "    \"A_EA electron_affinity [eV]\",\\\n",
    "    \"A_Mulliken  [eV]\",\\\n",
    "    \"A_Pauling\",\\\n",
    "    \"A_Martynov-Batsanov [ev^-1/2]\",\\\n",
    "    \"A_atomic_radius_rahm  [pm]\",\\\n",
    "    \"A_vdw_radius_uff [pm]\",\\\n",
    "    \"A_ionic_radius\",\\\n",
    "    \"B_Z\",\\\n",
    "    \"B_group\",\\\n",
    "    \"B_valence\",\\\n",
    "    \"B_vec/Z\",\\\n",
    "    \"B_n_d\",\\\n",
    "    \"B_atomic_volume pymatgen [cm3/mol]\",\\\n",
    "    \"B_Rdce [Å]\",\\\n",
    "    \"B_Rdve  [Å]\",\\\n",
    "    \"B_rs_max  [Å]\",\\\n",
    "    \"B_rd_max  [Å]\",\\\n",
    "    \"B_IE ionization energy [eV]\",\\\n",
    "    \"B_EA electron_affinity [eV]\",\\\n",
    "    \"B_Mulliken  [eV]\",\\\n",
    "    \"B_Pauling\",\\\n",
    "    \"B_Martynov-Batsanov [ev^-1/2]\",\\\n",
    "    \"B_atomic_radius_rahm  [pm]\",\\\n",
    "    \"B_vdw_radius_uff [pm]\",\\\n",
    "    \"B_ionic_radius\"]\n",
    "\n",
    "Y = df[labelname].abs().values\n",
    "X = df[materialfeatures + atomicfeatures]\n",
    "X_mat = df[materialfeatures]\n",
    "X_atm = df[atomicfeatures]\n",
    "\n",
    "# classification labbel for the dataset splitted by value\n",
    "cutval = 5.0\n",
    "Y_class = []\n",
    "for y in Y:\n",
    "    if y < -1.0*cutval:\n",
    "        Y_class.append(0)\n",
    "    elif y > -1.0*cutval and y < cutval:\n",
    "        Y_class.append(1)\n",
    "    else:\n",
    "        Y_class.append(2)\n",
    "\n",
    "Y_class = np.array(Y_class)\n",
    "# print the number of values for each class\n",
    "print(\"Number of values in class 0: \", len(Y_class[Y_class==0]))\n",
    "print(\"Number of values in class 1: \", len(Y_class[Y_class==1]))\n",
    "print(\"Number of values in class 2: \", len(Y_class[Y_class==2]))\n",
    "\n",
    "\n",
    "print(\"min label: \", min(Y))\n",
    "print(\"max label: \", max(Y))\n",
    "print(\"Number of values   greater than 0: \", len(Y[Y>0]))\n",
    "print(\"Number of values     lower than 0: \", len(Y[Y<0]))\n",
    "print(\"Number of values       equal to 0: \", len(Y[Y==0]))\n",
    "print(\"Number of values   greater than 5: \", len(Y[Y>cutval]))\n",
    "print(\"Number of values    lower than -5: \", len(Y[Y<-1.0*cutval]))\n",
    "print(\"Number of values between -5 and 5: \", len(Y[(Y>-1.0*cutval) & (Y<cutval)]))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(Y, bins=100)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of the labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRCUT = 0.95\n",
    "corr = X.corr()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "for i in range(upper.shape[0]):\n",
    "    for j in range(upper.shape[1]):\n",
    "        if upper.iloc[i,j] > CORRCUT:\n",
    "            print(\"%30s %30s %5.2f\"%(upper.columns[i], \\\n",
    "                                     upper.columns[j], \\\n",
    "                                        upper.iloc[i,j]))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] >CORRCUT)]\n",
    "print(\"Dropping features: \", to_drop)\n",
    "X = X.drop(X[to_drop], axis=1)\n",
    "\n",
    "corr_mat = X_mat.corr()\n",
    "upper = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > CORRCUT)]\n",
    "print(\"Dropping features: \", to_drop)\n",
    "X_mat = X_mat.drop(X_mat[to_drop], axis=1)\n",
    "\n",
    "corr_atm = X_atm.corr()\n",
    "upper = corr_atm.where(np.triu(np.ones(corr_atm.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > CORRCUT)]\n",
    "print(\"Dropping features: \", to_drop)\n",
    "X_atm = X_atm.drop(X_atm[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_df = X \n",
    "X_mat_df = X_mat\n",
    "X_atm_df = X_atm\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_mat = StandardScaler().fit_transform(X_mat)\n",
    "X_atm = StandardScaler().fit_transform(X_atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sumofvar = []\n",
    "ratioofvar = []\n",
    "\n",
    "first80 = False\n",
    "firtt90 = False\n",
    "numofcomptouse = 0\n",
    "for nc in range(1, X.shape[1]):\n",
    "    pca = PCA(n_components=nc)\n",
    "    pcs = pca.fit_transform(X)\n",
    "    sumofvar.append(sum(pca.explained_variance_ratio_))\n",
    "    #print(\"Explained variance ratio for \", nc, \" components: \", pca.explained_variance_ratio_)\n",
    "    ratioofvar.append(pca.explained_variance_ratio_[-1])\n",
    "    if sumofvar[-1] > 0.8 and not first80:\n",
    "        print(\"Number of components for 80% explained variance: \", nc, \" of \", X.shape[1])\n",
    "        first80 = True\n",
    "    if sumofvar[-1] > 0.9 and not firtt90:\n",
    "        print(\"Number of components for 90% explained variance: \", nc, \" of \", X.shape[1])\n",
    "        firtt90 = True\n",
    "        numofcomptouse = nc\n",
    "    #print(\"Explained variance ratio for \", nc, \" components: \", pca.explained_variance_ratio_)\n",
    "    #print(\"Explained variance for \", nc, \" components: \", pca.explained_variance_)\n",
    "    #print(\"Sum of explained variance for \", nc, \" components: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(sumofvar)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Explained variance\")\n",
    "plt.title(\"Explained variance ratio\")\n",
    "plt.show()\n",
    "\n",
    "# plot the explained variance ratio\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ratioofvar)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Explained variance\")\n",
    "plt.title(\"Explained variance ratio\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "first80 = False\n",
    "firtt90 = False\n",
    "numofcomptouse_mat = 0\n",
    "sumofvar = []\n",
    "ratioofvar = []\n",
    "for nc in range(1, X_mat.shape[1]):\n",
    "    pca = PCA(n_components=nc)\n",
    "    pcs = pca.fit_transform(X_mat)\n",
    "    sumofvar.append(sum(pca.explained_variance_ratio_))\n",
    "    #print(\"Explained variance ratio for \", nc, \" components: \", pca.explained_variance_ratio_)\n",
    "    ratioofvar.append(pca.explained_variance_ratio_[-1])\n",
    "    if sumofvar[-1] > 0.8 and not first80:\n",
    "        print(\"Number of components for 80% explained variance: \", nc, \" of \", X_mat.shape[1])\n",
    "        first80 = True\n",
    "    if sumofvar[-1] > 0.9 and not firtt90:\n",
    "        print(\"Number of components for 90% explained variance: \", nc, \" of \", X_mat.shape[1])\n",
    "        firtt90 = True\n",
    "        numofcomptouse_mat = nc\n",
    "\n",
    "first80 = False\n",
    "firtt90 = False\n",
    "numofcomptouse_atm = 0\n",
    "sumofvar = []\n",
    "ratioofvar = []\n",
    "\n",
    "for nc in range(1, X_atm.shape[1]):\n",
    "    pca = PCA(n_components=nc)\n",
    "    pcs = pca.fit_transform(X_atm)\n",
    "    sumofvar.append(sum(pca.explained_variance_ratio_))\n",
    "    #print(\"Explained variance ratio for \", nc, \" components: \", pca.explained_variance_ratio_)\n",
    "    ratioofvar.append(pca.explained_variance_ratio_[-1])\n",
    "    if sumofvar[-1] > 0.8 and not first80:\n",
    "        print(\"Number of components for 80% explained variance: \", nc, \" of \", X_atm.shape[1])\n",
    "        first80 = True\n",
    "    if sumofvar[-1] > 0.9 and not firtt90:\n",
    "        print(\"Number of components for 90% explained variance: \", nc, \" of \", X_atm.shape[1])\n",
    "        firtt90 = True\n",
    "        numofcomptouse_atm = nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loeading plot for the first components\n",
    "pca = PCA(n_components=numofcomptouse)\n",
    "pcs = pca.fit_transform(X)\n",
    "loading = pca.components_\n",
    "loading = np.transpose(loading)\n",
    "print(\"Loading shape: \", loading.shape)\n",
    "\n",
    "usecomps = 4\n",
    "\n",
    "for ncomp in range(usecomps):\n",
    "    print(\"Explained variance for component \", ncomp+1, \\\n",
    "          \": \", pca.explained_variance_ratio_[ncomp])\n",
    "    #print(loading[:, ncomp])\n",
    "loading = pd.DataFrame(loading, columns=[\"PC\"+str(i) for i in range(1, numofcomptouse+1)])\n",
    "loading[\"Feature\"] = X_df.columns\n",
    "loading = loading.set_index(\"Feature\")\n",
    "loading = loading.abs()\n",
    "loading = loading.sort_values(by=\"PC1\", ascending=False)\n",
    "\n",
    "#loading.plot.bar(stacked=True, figsize=(20, 10))\n",
    "#plt.show()\n",
    "\n",
    "# print the most important features for the first 16 components\n",
    "for ncomp in range(usecomps):\n",
    "    print(\"Most important features for component \", ncomp+1)\n",
    "    print(loading[\"PC\"+str(ncomp+1)].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatterplot of the first two components using different color for each class\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pcs[Y_class==0, 0], pcs[Y_class==0, 1], c=\"red\", label=\"Class 0\")\n",
    "plt.scatter(pcs[Y_class==1, 0], pcs[Y_class==1, 1], c=\"blue\", label=\"Class 1\")\n",
    "plt.scatter(pcs[Y_class==2, 0], pcs[Y_class==2, 1], c=\"green\", label=\"Class 2\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of the dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatterplot of the first three components using different color for each class\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pcs[Y_class==0, 0], pcs[Y_class==0, 1], pcs[Y_class==0, 2], c=\"red\", label=\"Class 0\")\n",
    "ax.scatter(pcs[Y_class==1, 0], pcs[Y_class==1, 1], pcs[Y_class==1, 2], c=\"blue\", label=\"Class 1\")\n",
    "ax.scatter(pcs[Y_class==2, 0], pcs[Y_class==2, 1], pcs[Y_class==2, 2], c=\"green\", label=\"Class 2\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loeading plot for the first components\n",
    "pca = PCA(n_components=numofcomptouse_mat)\n",
    "pcs = pca.fit_transform(X_mat)\n",
    "loading = pca.components_\n",
    "loading = np.transpose(loading)\n",
    "print(\"Loading shape: \", loading.shape)\n",
    "\n",
    "usecomps = 4\n",
    "\n",
    "for ncomp in range(usecomps):\n",
    "    print(\"Explained variance for component \", ncomp+1, \\\n",
    "          \": \", pca.explained_variance_ratio_[ncomp])\n",
    "    #print(loading[:, ncomp])\n",
    "loading = pd.DataFrame(loading, columns=[\"PC\"+str(i) for i in range(1, numofcomptouse_mat+1)])\n",
    "loading[\"Feature\"] = X_mat_df.columns\n",
    "loading = loading.set_index(\"Feature\")\n",
    "loading = loading.abs()\n",
    "loading = loading.sort_values(by=\"PC1\", ascending=False)\n",
    "\n",
    "#loading.plot.bar(stacked=True, figsize=(20, 10))\n",
    "#plt.show()\n",
    "\n",
    "# print the most important features for the first 16 components\n",
    "for ncomp in range(usecomps):\n",
    "    print(\"Most important features for component \", ncomp+1)\n",
    "    print(loading[\"PC\"+str(ncomp+1)].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatterplot of the first two components using different color for each class\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pcs[Y_class==0, 0], pcs[Y_class==0, 1], c=\"red\", label=\"Class 0\")\n",
    "plt.scatter(pcs[Y_class==1, 0], pcs\n",
    "            [Y_class==1, 1], c=\"blue\", label=\"Class 1\")\n",
    "plt.scatter(pcs[Y_class==2, 0], pcs\n",
    "            [Y_class==2, 1], c=\"green\", label=\"Class 2\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of the dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatterplot of the first three components using different color for each class\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pcs[Y_class==0, 0], pcs[Y_class==0, 1], pcs[Y_class==0, 2], c=\"red\", label=\"Class 0\")\n",
    "ax.scatter(pcs[Y_class==1, 0], pcs[Y_class==1, 1], pcs[Y_class==1, 2], c=\"blue\", label=\"Class 1\")\n",
    "ax.scatter(pcs[Y_class==2, 0], pcs[Y_class==2, 1], pcs[Y_class==2, 2], c=\"green\", label=\"Class 2\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of the dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loeading plot for the first components\n",
    "pca = PCA(n_components=numofcomptouse_atm)\n",
    "pcs = pca.fit_transform(X_atm)\n",
    "loading = pca.components_\n",
    "loading = np.transpose(loading)\n",
    "print(\"Loading shape: \", loading.shape)\n",
    "\n",
    "usecomps = 4\n",
    "\n",
    "for ncomp in range(usecomps):\n",
    "    print(\"Explained variance for component \", ncomp+1, \\\n",
    "          \": \", pca.explained_variance_ratio_[ncomp])\n",
    "    #print(loading[:, ncomp])\n",
    "loading = pd.DataFrame(loading, columns=[\"PC\"+str(i) for i in \n",
    "                                         range(1, numofcomptouse_atm+1)])\n",
    "loading[\"Feature\"] = X_atm_df.columns\n",
    "loading = loading.set_index(\"Feature\")\n",
    "loading = loading.abs()\n",
    "loading = loading.sort_values(by=\"PC1\", ascending=False)\n",
    "\n",
    "#loading.plot.bar(stacked=True, figsize=(20, 10))\n",
    "#plt.show()\n",
    "\n",
    "# print the most important features for the first 16 components\n",
    "for ncomp in range(usecomps):\n",
    "    print(\"Most important features for component \", ncomp+1)\n",
    "    print(loading[\"PC\"+str(ncomp+1)].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatterplot of the first two components using different color for each class\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pcs[Y_class==0, 0], pcs\n",
    "            [Y_class==0, 1], c=\"red\", label=\"Class 0\")\n",
    "plt.scatter(pcs[Y_class==1, 0], pcs\n",
    "            [Y_class==1, 1], c=\"blue\", label=\"Class 1\")\n",
    "plt.scatter(pcs[Y_class==2, 0], pcs\n",
    "            [Y_class==2, 1], c=\"green\", label=\"Class 2\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of the dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatterplot of the first three components using different color for each class\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pcs[Y_class==0, 0], pcs\n",
    "            [Y_class==0, 1], pcs\n",
    "            [Y_class==0, 2], c=\"red\", label=\"Class 0\")\n",
    "ax.scatter(pcs[Y_class==1, 0], pcs\n",
    "            [Y_class==1, 1], pcs\n",
    "            [Y_class==1, 2], c=\"blue\", label=\"Class 1\")\n",
    "ax.scatter(pcs[Y_class==2, 0], pcs\n",
    "            [Y_class==2, 1], pcs\n",
    "            [Y_class==2, 2], c=\"green\", label=\"Class 2\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA of the dataset\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
